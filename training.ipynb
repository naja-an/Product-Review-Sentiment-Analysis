{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "799670e4",
      "metadata": {
        "id": "799670e4"
      },
      "source": [
        "# Sentiment Analysis using Word2Vec + LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be1d3f00",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "be1d3f00",
        "outputId": "96a484b4-1155-4db0-d6ad-2a039c369d99"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from gensim.models import Word2Vec\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "nltk.download('punkt_tab')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b004743a",
      "metadata": {
        "id": "b004743a"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Load and preprocess dataset\n",
        "data = pd.read_csv('data/Reviews.csv')\n",
        "data = data[['Text', 'Score']].dropna()\n",
        "\n",
        "# Convert scores to sentiment labels\n",
        "def to_sentiment(score):\n",
        "    if score >= 4:\n",
        "        return 1  # Positive\n",
        "    elif score <= 2:\n",
        "        return 0  # Negative\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "data['Sentiment'] = data['Score'].apply(to_sentiment)\n",
        "data = data.dropna(subset=['Sentiment'])\n",
        "data['Sentiment'] = data['Sentiment'].astype(int)\n",
        "\n",
        "# Clean text\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'[^a-zA-Z ]', '', text.lower())\n",
        "    return text\n",
        "\n",
        "data['Clean_Text'] = data['Text'].apply(clean_text)\n",
        "\n",
        "# Word Tokens\n",
        "data['Tokens'] = data['Clean_Text'].apply(word_tokenize)\n",
        "\"\"\"\n",
        "We first use nltk.word_tokenize() to split each sentence into a list of words like:\n",
        "\n",
        "\"This is good\" → [\"This\", \"is\", \"good\"]\n",
        "\n",
        "This gives us clean input for training a Word2Vec embedding model.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6ac77da",
      "metadata": {
        "id": "c6ac77da"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Train Word2Vec model\n",
        "\"\"\"Word2Vec learns a dense vector representation (embedding) for each word based on context.\n",
        "Each word becomes a 300-dimensional numeric vector capturing meaning (similar words have similar vectors).\n",
        "The embeddings will later be used to initialize the LSTM model’s embedding layer.\"\"\"\n",
        "w2v_model = Word2Vec(sentences=data['Tokens'], vector_size=300, window=5, min_count=2, workers=4)\n",
        "vocab = w2v_model.wv.key_to_index\n",
        "embedding_dim = 300\n",
        "\n",
        "# Tokenize text for LSTM\n",
        "\"\"\"The LSTM model can’t take words directly — it needs integer-encoded sequences (like [5, 23, 67, 1, ...]).\n",
        "\n",
        "The Keras Tokenizer builds a word-index mapping and converts each tokenized review into a list of word IDs.\n",
        "\"\"\"\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(data['Tokens'])\n",
        "sequences = tokenizer.texts_to_sequences(data['Tokens'])\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "max_len = 300\n",
        "X = pad_sequences(sequences, maxlen=max_len, padding='post', truncating='post')\n",
        "y = data['Sentiment'].values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "221fdbc6",
      "metadata": {
        "id": "221fdbc6"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Create embedding matrix from Word2Vec\n",
        "\"\"\"We link the Word2Vec vectors to the corresponding token indices used by Keras.\n",
        "\n",
        "The LSTM’s embedding layer will use this matrix so that each word ID gets the right 300-D vector from Word2Vec.\"\"\"\n",
        "embedding_matrix = np.zeros((len(word_index) + 1, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    if word in w2v_model.wv:\n",
        "        embedding_matrix[i] = w2v_model.wv[word]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "d99929d3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d99929d3",
        "outputId": "08fac20a-d9d3-4f8d-bd8f-0d88befa9f65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class Weights: {0: 3.2033491729872976, 1: 0.592477879845518}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Compute class weights\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "class_weights = dict(enumerate(class_weights))\n",
        "print(\"Class Weights:\", class_weights)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "629b878a",
      "metadata": {},
      "source": [
        "## Summary for the model pipline"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5580070",
      "metadata": {},
      "source": [
        "| Layer                    | Purpose                                     | Key Benefit                      |\n",
        "| ------------------------ | ------------------------------------------- | -------------------------------- |\n",
        "| **Embedding (Word2Vec)** | Map word indices to semantic vectors        | Leverage pretrained word meaning |\n",
        "| **BiLSTM (64 units)**    | Learn sequence context from both directions | Understand full sentence meaning |\n",
        "| **Dropout (0.4)**        | Regularization                              | Prevent overfitting              |\n",
        "| **Dense (64, ReLU)**     | Learn nonlinear combinations                | Add model capacity               |\n",
        "| **Dropout (0.3)**        | Regularization                              | Improve generalization           |\n",
        "| **Dense (1, Sigmoid)**   | Output probability                          | Binary classification            |\n",
        "| **Adam Optimizer**       | Efficient gradient updates                  | Fast & stable convergence        |\n",
        "| **Binary Crossentropy**  | Measure prediction error                    | Ideal for binary targets         |\n",
        "| **Accuracy Metric**      | Evaluate performance                        | Easy to interpret                |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6baf31f3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "id": "6baf31f3",
        "outputId": "ff031029-3dde-42d9-fb41-b881a7216bca"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">63,677,100</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │    \u001b[38;5;34m63,677,100\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">63,677,100</span> (242.91 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m63,677,100\u001b[0m (242.91 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">63,677,100</span> (242.91 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m63,677,100\u001b[0m (242.91 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "# Build LSTM model\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=len(word_index)+1, output_dim=embedding_dim, weights=[embedding_matrix],\n",
        "              input_length=max_len, trainable=False),\n",
        "    Bidirectional(LSTM(64, return_sequences=False)),\n",
        "    Dropout(0.4),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "optimizer = Adam(learning_rate=1e-4)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "91e89c35",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91e89c35",
        "outputId": "57944767-0acb-4da4-84f6-9436b54e0c78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/8\n",
            "\u001b[1m5259/5259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 28ms/step - accuracy: 0.7290 - loss: 0.4972 - val_accuracy: 0.9004 - val_loss: 0.2495\n",
            "Epoch 2/8\n",
            "\u001b[1m5259/5259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 28ms/step - accuracy: 0.8804 - loss: 0.2852 - val_accuracy: 0.8949 - val_loss: 0.2541\n",
            "Epoch 3/8\n",
            "\u001b[1m5259/5259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 28ms/step - accuracy: 0.9057 - loss: 0.2309 - val_accuracy: 0.9110 - val_loss: 0.2281\n",
            "Epoch 4/8\n",
            "\u001b[1m5259/5259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 28ms/step - accuracy: 0.9208 - loss: 0.1972 - val_accuracy: 0.9432 - val_loss: 0.1509\n",
            "Epoch 5/8\n",
            "\u001b[1m5259/5259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 28ms/step - accuracy: 0.9292 - loss: 0.1783 - val_accuracy: 0.9330 - val_loss: 0.1823\n",
            "Epoch 6/8\n",
            "\u001b[1m5259/5259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 28ms/step - accuracy: 0.9355 - loss: 0.1626 - val_accuracy: 0.9415 - val_loss: 0.1588\n",
            "Epoch 7/8\n",
            "\u001b[1m5259/5259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 28ms/step - accuracy: 0.9423 - loss: 0.1480 - val_accuracy: 0.9443 - val_loss: 0.1495\n",
            "Epoch 8/8\n",
            "\u001b[1m5259/5259\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 29ms/step - accuracy: 0.9451 - loss: 0.1384 - val_accuracy: 0.9460 - val_loss: 0.1428\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Train model\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=8,\n",
        "    batch_size=64,\n",
        "    validation_split=0.2,\n",
        "    class_weight=class_weights\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "89311791",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89311791",
        "outputId": "8bed33c8-272b-4a7a-ec5d-7178ef816261"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m3287/3287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 11ms/step - accuracy: 0.9467 - loss: 0.1403\n",
            "Test Accuracy: 0.946\n",
            "\u001b[1m3287/3287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 9ms/step\n",
            "1    0.809676\n",
            "0    0.190324\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Evaluate\n",
        "loss, acc = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {acc:.3f}\")\n",
        "\n",
        "# Check prediction distribution\n",
        "preds = (model.predict(X_test) > 0.5).astype(int)\n",
        "print(pd.Series(preds.flatten()).value_counts(normalize=True))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XVspAxcrKHF-",
      "metadata": {
        "id": "XVspAxcrKHF-"
      },
      "outputs": [],
      "source": [
        "# Function to predict with the model\n",
        "def predict_sentiment(text):\n",
        "    # The model expects sequences of token indices, not vector sequences from preprocess_text\n",
        "    # So, we need to use the tokenizer and pad_sequences as done for training data\n",
        "\n",
        "    # Clean text\n",
        "    cleaned_text = clean_text(text)\n",
        "    # Tokenize text\n",
        "    tokens = word_tokenize(cleaned_text)\n",
        "    # Convert tokens to sequences\n",
        "    sequence = tokenizer.texts_to_sequences([tokens])\n",
        "    # Pad sequences\n",
        "    padded_sequence = pad_sequences(sequence, maxlen=max_len, padding='post', truncating='post')\n",
        "\n",
        "    prediction = model.predict(padded_sequence)\n",
        "    print(prediction)\n",
        "    if prediction[0][0] >0.5:\n",
        "        return \"Positive\"\n",
        "    else:\n",
        "        return \"Negative\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "WGuEKIvHK98s",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGuEKIvHK98s",
        "outputId": "15ecda50-6f0c-4b3a-a0a6-6a10c2a4a3ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "[[0.92120713]]\n"
          ]
        }
      ],
      "source": [
        "test_positive = predict_sentiment(\"The smell isn't bad at all and only mildly stings on sensitive areas, but it doesn't last long (60-120 seconds) and the 'burning' usually stops. As for the hair, it gets annihilated... I've never seen anything like it, it was effortless and clean-up is pretty easy all things considered. I'm in love with this product... Works for men too!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "8f4FUHBGLIvl",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8f4FUHBGLIvl",
        "outputId": "7ae63814-1352-49bc-ed69-770fcd4c01ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "[[0.01586174]]\n"
          ]
        }
      ],
      "source": [
        "test_negative = predict_sentiment(\"\"\"I used this product several years ago and it was quite effective so I decided to try again.\n",
        "\n",
        "Unfortunately, this product is not as effective. Despite following the long list of directions and preparation of my skin, it took many times to get most of the hair removed and it still left some stranglers.\n",
        "\n",
        "In addition, somehow this product is messier than before.\n",
        "\n",
        "Formula may have been changed and I missed that part but it was not at expected.\n",
        "\n",
        "Lastly, because of the multiple applications needed it took nearly half the container for one session.\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "_q8szfrzThHH",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_q8szfrzThHH",
        "outputId": "08d3a3f5-1866-4229-cc1f-eb117d453614"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('Positive', 'Negative')"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_positive, test_negative"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Ku_Sg3sNLLRG",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ku_Sg3sNLLRG",
        "outputId": "c1913013-f65c-49cd-9c18-ca8a253b078b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved\n"
          ]
        }
      ],
      "source": [
        "# save the model, word2vec model abd tokenizer\n",
        "if test_positive == 'Positive' and test_negative == 'Negative':\n",
        "  print('Model saved')\n",
        "  model.save('model/sentiment_analysis_model.h5')\n",
        "  w2v_model.save('model/word2vec_model.bin')\n",
        "  import pickle\n",
        "  with open('model/tokenizer.pickle', 'wb') as handle:\n",
        "      pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "696c6b58",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "sentiment_analysis",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
